{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create Azure ML Environment for experimenting, training and inferencing.\n",
        "\n",
        "The following snippet shows you how to create a reproducible Azure ML environment, it will use a requirements.txt file which is also used when creating the Compute Instance, there we use a startup script that will create a virtual environment for us.\n",
        "\n",
        "This keeps in sync the virtual environment with the Azure ML Environment, saving headaches later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1722856603114
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment registered successfully.\n"
          ]
        }
      ],
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core import Workspace\n",
        "import os\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config(path='Users/levm38/config.json')\n",
        "\n",
        "# Create the environment\n",
        "env = Environment.from_pip_requirements(name=\"my-environment\", file_path=\"requirements.txt\")\n",
        "\n",
        "# Register the environment\n",
        "env.register(workspace=ws)\n",
        "print(\"Environment registered successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Trigger train.py\n",
        "\n",
        "Then train.py is where you put your training script, and the snippet below just triggers it using Azure ML SDK."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1722856613741
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace\n",
        "ws = Workspace.from_config(path='Users/levm38/config.json')\n",
        "\n",
        "# Define the experiment\n",
        "experiment = Experiment(workspace=ws, name='my-experiment')\n",
        "\n",
        "# Load the registered environment\n",
        "env = Environment.get(workspace=ws, name=\"my-environment\")\n",
        "\n",
        "# Define the run configuration\n",
        "run_config = RunConfiguration()\n",
        "run_config.environment = env\n",
        "\n",
        "# Define script parameters\n",
        "script_params = {\n",
        "    '--data': 'data.csv'  # Path to the sample data file\n",
        "}\n",
        "\n",
        "# Configure the script run\n",
        "src = ScriptRunConfig(source_directory='',\n",
        "                      script='train.py',\n",
        "                      arguments=[f'{k} {v}' for k, v in script_params.items()],\n",
        "                      run_config=run_config)\n",
        "\n",
        "# Submit the experiment\n",
        "run = experiment.submit(src)\n",
        "run.wait_for_completion(show_output=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Train.py Contents\n",
        "\n",
        "Before you code train.py, feel free to test it inside a Jupyter cell, then just use that code as train.py file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1722856614642
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-05 11:16:55,048 - INFO - Loading data from: data.csv\n",
            "2024-08-05 11:16:55,058 - INFO - Data loaded successfully.\n",
            "2024-08-05 11:16:55,060 - INFO - Training model...\n",
            "2024-08-05 11:16:55,156 - INFO - Model trained successfully.\n",
            "2024-08-05 11:16:55,235 - INFO - Model saved successfully.\n",
            "2024-08-05 11:16:55,242 - INFO - Model accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import logging\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger()\n",
        "\n",
        "# Mock arguments for debugging\n",
        "class Args:\n",
        "    data = 'data.csv'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Validate arguments\n",
        "if not args.data:\n",
        "    logger.error(\"No data path provided. Please specify the --data argument.\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "if not os.path.isfile(args.data):\n",
        "    logger.error(f\"Data file not found: {args.data}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Load data\n",
        "try:\n",
        "    logger.info(f\"Loading data from: {args.data}\")\n",
        "    data = pd.read_csv(args.data)\n",
        "    logger.info(\"Data loaded successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to load data: {e}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "try:\n",
        "    X = data.drop('target', axis=1)\n",
        "    y = data['target']\n",
        "except KeyError as e:\n",
        "    logger.error(f\"KeyError during data processing: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Train model\n",
        "try:\n",
        "    logger.info(\"Training model...\")\n",
        "    model = RandomForestClassifier()\n",
        "    model.fit(X, y)\n",
        "    logger.info(\"Model trained successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to train model: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Save the model\n",
        "try:\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "    joblib.dump(model, 'outputs/model.pkl')\n",
        "    logger.info(\"Model saved successfully.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to save model: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Print accuracy\n",
        "try:\n",
        "    y_pred = model.predict(X)\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    logger.info(f\"Model accuracy: {accuracy}\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to calculate accuracy: {e}\")\n",
        "    sys.exit(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Register the model\n",
        "\n",
        "The scripts above produce a model in picke format, be sure to register it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1722856615927
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Model\n",
        "\n",
        "ws = Workspace.from_config(path='Users/levm38/config.json')\n",
        "\n",
        "# Register the model\n",
        "model = Model.register(workspace=ws,\n",
        "                       model_path='outputs/model.pkl',\n",
        "                       model_name='random_forest_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create deployment configuration\n",
        "\n",
        "The snippet below will create the deployment configuration and the inference endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1722857708052
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "\n",
        "# Initialize MLClient\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient.from_config(credential)\n",
        "\n",
        "# Define the managed online endpoint\n",
        "endpoint_name = 'my-managed-online-endpoint'\n",
        "\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"My managed online endpoint for model deployment\",\n",
        "    auth_mode=\"key\"\n",
        ")\n",
        "\n",
        "# Create the endpoint\n",
        "ml_client.begin_create_or_update(endpoint).result()\n",
        "\n",
        "# Define the deployment\n",
        "deployment_name = 'my-deployment'\n",
        "\n",
        "# Use the registered model\n",
        "model_id = 'random_forest_model:7'  # Ensure you use the correct model ID and version\n",
        "\n",
        "# Retrieve the registered environment\n",
        "environment = ml_client.environments.get(name=\"my-environment\", version=\"8\")  # Adjust the version as needed\n",
        "\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=deployment_name,\n",
        "    endpoint_name=endpoint_name,\n",
        "    model=model_id,  # Reference the registered model ID\n",
        "    environment=environment.id,  # Use the registered environment ID\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code='./',  # Assuming 'score.py' is in the current directory\n",
        "        scoring_script='score.py'\n",
        "    ),\n",
        "    instance_type='Standard_F2s_v2',\n",
        "    instance_count=1\n",
        ")\n",
        "\n",
        "# Create the deployment\n",
        "ml_client.begin_create_or_update(deployment).result()\n",
        "\n",
        "# Get the endpoint details\n",
        "endpoint = ml_client.online_endpoints.get(name=endpoint_name)\n",
        "\n",
        "print(f\"Managed online endpoint state: {endpoint.provisioning_state}\")\n",
        "print(f\"Managed online endpoint scoring URI: {endpoint.scoring_uri}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# score.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1722856621755
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the init function to load the model\n",
        "def init():\n",
        "    global model\n",
        "    model_path =  os.path.join(os.getcwd(), 'outputs/model.pkl') \n",
        "    print(f\"Model path: {model_path}\")\n",
        "    \n",
        "    # Check if the file exists\n",
        "    if not os.path.isfile(model_path):\n",
        "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
        "    \n",
        "    model = joblib.load(model_path)\n",
        "    print(f\"Model loaded successfully from: {model_path}\")\n",
        "\n",
        "# Define the run function to handle requests\n",
        "def run(raw_data):\n",
        "    try:\n",
        "        data = json.loads(raw_data)\n",
        "        df = pd.DataFrame(data)\n",
        "        \n",
        "        # Define required columns\n",
        "        required_columns = ['feature1', 'feature2', 'feature3']\n",
        "        \n",
        "        # Check if required columns are present\n",
        "        for col in required_columns:\n",
        "            if col not in df.columns:\n",
        "                raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(df)\n",
        "        \n",
        "        return json.dumps(predictions.tolist())\n",
        "    \n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return json.dumps({'error': error})\n",
        "\n",
        "# Local test\n",
        "init()\n",
        "\n",
        "# Create some test data\n",
        "test_data = {\n",
        "    \"feature1\": [1, 5],\n",
        "    \"feature2\": [2, 6],\n",
        "    \"feature3\": [3, 7]\n",
        "}\n",
        "raw_data = json.dumps(test_data)\n",
        "\n",
        "# Run the scoring function\n",
        "result = run(raw_data)\n",
        "print(\"Inference Result:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Testing the inference endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1722860120370
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'\"[0, 1]\"'\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import json\n",
        "import os\n",
        "import ssl\n",
        "\n",
        "def allowSelfSignedHttps(allowed):\n",
        "    # bypass the server certificate verification on client side\n",
        "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
        "        ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
        "\n",
        "# Request data goes here\n",
        "# The example below assumes JSON formatting which may be updated\n",
        "# depending on the format your endpoint expects.\n",
        "# More information can be found here:\n",
        "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
        "data = {\n",
        "    \"feature1\": [1, 5],\n",
        "    \"feature2\": [2, 6],\n",
        "    \"feature3\": [3, 7]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "body = str.encode(json.dumps(data))\n",
        "\n",
        "url = 'https://my-managed-online-endpoint.swedencentral.inference.ml.azure.com/score'\n",
        "# Replace this with the primary/secondary key, AMLToken, or Microsoft Entra ID token for the endpoint\n",
        "api_key = 'SHTW08RgiAc299VcZgqIbnaGD1cU3ePw'\n",
        "if not api_key:\n",
        "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
        "\n",
        "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
        "# Remove this header to have the request observe the endpoint traffic rules\n",
        "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'my-deployment' }\n",
        "\n",
        "req = urllib.request.Request(url, body, headers)\n",
        "\n",
        "try:\n",
        "    response = urllib.request.urlopen(req)\n",
        "\n",
        "    result = response.read()\n",
        "    print(result)\n",
        "except urllib.error.HTTPError as error:\n",
        "    print(\"The request failed with status code: \" + str(error.code))\n",
        "\n",
        "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
        "    print(error.info())\n",
        "    print(error.read().decode(\"utf8\", 'ignore'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
